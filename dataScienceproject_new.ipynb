{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flGgKutGgAqC",
        "outputId": "29383100-3fc3-4d41-a1b0-02b7f87bdd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated patients: 18094\n",
            "Observation rows: 43200\n",
            "Crowded threshold (quantile=0.72): 21\n",
            "Class balance (proportion):\n",
            " Crowded\n",
            "0    0.728958\n",
            "1    0.271042\n",
            "Name: proportion, dtype: float64\n",
            "Feature columns count: 12\n",
            "\n",
            "Model Accuracy: 0.8768518518518519\n",
            "\n",
            "Confusion Matrix:\n",
            " [[5421  877]\n",
            " [ 187 2155]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9667    0.8607    0.9106      6298\n",
            "           1     0.7108    0.9202    0.8020      2342\n",
            "\n",
            "    accuracy                         0.8769      8640\n",
            "   macro avg     0.8387    0.8905    0.8563      8640\n",
            "weighted avg     0.8973    0.8769    0.8812      8640\n",
            "\n",
            "Accuracy < 90% — training a second RF and ensemble to improve robustness...\n",
            "Ensemble Accuracy: 0.8767361111111112\n",
            "\n",
            "Saved primary model to outputs/hospital_crowd_rf_model.joblib and features to outputs/feature_columns.csv\n",
            "Saved heatmap to outputs/heatmap_day_hour.png\n",
            "Saved line plot to outputs/crowd_prob_line_Wed.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# -----------------------\n",
        "# 0. reproducibility & output folder\n",
        "# -----------------------\n",
        "np.random.seed(42)\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# -----------------------\n",
        "# 1. Generate synthetic dataset with strong time-dependent pattern\n",
        "# -----------------------\n",
        "n_days = 60\n",
        "mean_patients_per_day = 300\n",
        "days = pd.date_range(start=\"2024-01-01\", periods=n_days, freq=\"D\")\n",
        "\n",
        "minute_range = np.arange(8*60, 20*60)  # 08:00 (480) .. 19:59 (1199) inclusive start\n",
        "n_minutes = len(minute_range)  # 720\n",
        "\n",
        "# Build a probability distribution over minutes (two peaks: morning & afternoon)\n",
        "center1 = (9*60 + 30)    # 09:30 -> 570\n",
        "center2 = (15*60)        # 15:00 -> 900\n",
        "sigma = 60.0             # spread of peaks (minutes)\n",
        "\n",
        "minutes_abs = minute_range\n",
        "# gaussian peaks (use absolute minute values)\n",
        "g1 = np.exp(-0.5 * ((minutes_abs - center1)/sigma)**2)\n",
        "g2 = 1.0 * np.exp(-0.5 * ((minutes_abs - center2)/ (sigma*1.2))**2)  # slightly wider afternoon peak\n",
        "baseline = 0.1  # baseline probability across all minutes\n",
        "weights = g1 + g2 + baseline\n",
        "weights = weights / weights.sum()  # normalize -> sum 1\n",
        "\n",
        "patients = []\n",
        "for day in days:\n",
        "    dow = day.strftime(\"%a\")  # Mon, Tue, ...\n",
        "    n_pat = np.random.poisson(mean_patients_per_day)\n",
        "    # sample arrival minutes according to weighted distribution\n",
        "    arr_minutes = np.random.choice(minute_range, size=n_pat, p=weights)\n",
        "    # durations: mostly short, some moderate; use gamma-like distribution\n",
        "    durations = (np.random.gamma(shape=2.0, scale=15.0, size=n_pat).astype(int) + 5)\n",
        "    exit_minutes = np.minimum(arr_minutes + durations, 20*60)  # cap at closing\n",
        "    for a, e in zip(arr_minutes, exit_minutes):\n",
        "        if e > a:\n",
        "            patients.append({\n",
        "                \"date\": day,\n",
        "                \"day_of_week\": dow,\n",
        "                \"entry_min\": int(a),\n",
        "                \"exit_min\": int(e)\n",
        "            })\n",
        "\n",
        "patients_df = pd.DataFrame(patients)\n",
        "print(\"Generated patients:\", len(patients_df))\n",
        "\n",
        "# -----------------------\n",
        "# 2. Minute-level occupancy (observations)\n",
        "# -----------------------\n",
        "records = []\n",
        "for day, group in patients_df.groupby(\"date\"):\n",
        "    dow = day.strftime(\"%a\")\n",
        "    # for each minute between 08:00 and 20:00 (minute_range)\n",
        "    for minute in minute_range:\n",
        "        cnt = ((group[\"entry_min\"] <= minute) & (group[\"exit_min\"] > minute)).sum()\n",
        "        records.append({\n",
        "            \"date\": day,\n",
        "            \"day_of_week\": dow,\n",
        "            \"minute_of_day\": int(minute),\n",
        "            \"hour\": int(minute // 60),\n",
        "            \"minute\": int(minute % 60),\n",
        "            \"num_present\": int(cnt)\n",
        "        })\n",
        "\n",
        "obs = pd.DataFrame(records)\n",
        "print(\"Observation rows:\", len(obs))\n",
        "\n",
        "# -----------------------\n",
        "# 3. Create target (make threshold chosen to give decent positive proportion ~25-35%)\n",
        "# -----------------------\n",
        "threshold_quantile = 0.72\n",
        "threshold = int(obs[\"num_present\"].quantile(threshold_quantile))\n",
        "obs[\"Crowded\"] = (obs[\"num_present\"] > threshold).astype(int)\n",
        "print(f\"Crowded threshold (quantile={threshold_quantile}):\", threshold)\n",
        "print(\"Class balance (proportion):\\n\", obs[\"Crowded\"].value_counts(normalize=True).rename(\"proportion\"))\n",
        "\n",
        "# -----------------------\n",
        "# 4. Feature engineering\n",
        "# -----------------------\n",
        "# cyclical encoding of minute_of_day\n",
        "obs[\"sin_time\"] = np.sin(2 * np.pi * obs[\"minute_of_day\"] / (24*60))\n",
        "obs[\"cos_time\"] = np.cos(2 * np.pi * obs[\"minute_of_day\"] / (24*60))\n",
        "obs[\"minute_of_day_norm\"] = (obs[\"minute_of_day\"] - obs[\"minute_of_day\"].min()) / (obs[\"minute_of_day\"].max() - obs[\"minute_of_day\"].min())\n",
        "obs[\"is_weekend\"] = obs[\"day_of_week\"].isin([\"Sat\", \"Sun\"]).astype(int)\n",
        "\n",
        "# base feature set (do NOT include num_present)\n",
        "feature_df = obs[[\"sin_time\", \"cos_time\", \"minute_of_day\", \"hour\", \"minute\", \"is_weekend\", \"day_of_week\"]].copy()\n",
        "target = obs[\"Crowded\"].copy()\n",
        "\n",
        "# one-hot day_of_week\n",
        "X = pd.get_dummies(feature_df, columns=[\"day_of_week\"], drop_first=True)\n",
        "y = target\n",
        "\n",
        "print(\"Feature columns count:\", X.shape[1])\n",
        "\n",
        "# -----------------------\n",
        "# 5. Train / Test split (stratified)\n",
        "# -----------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "# -----------------------\n",
        "# 6. Model: RandomForest with tuned-ish hyperparameters\n",
        "#     Using class_weight='balanced_subsample' so each tree sees balanced sample weights\n",
        "# -----------------------\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    max_depth=16,\n",
        "    min_samples_leaf=3,\n",
        "    class_weight=\"balanced_subsample\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -----------------------\n",
        "# 7. Evaluation\n",
        "# -----------------------\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, digits=4)\n",
        "\n",
        "print(\"\\nModel Accuracy:\", acc)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "# If accuracy is still below expectation, we also try a quick ensemble: train a second RF with different seed and average\n",
        "if acc < 0.90:\n",
        "    print(\"Accuracy < 90% — training a second RF and ensemble to improve robustness...\")\n",
        "    model2 = RandomForestClassifier(\n",
        "        n_estimators=400,\n",
        "        max_depth=18,\n",
        "        min_samples_leaf=2,\n",
        "        class_weight=\"balanced_subsample\",\n",
        "        n_jobs=-1,\n",
        "        random_state=7\n",
        "    )\n",
        "    model2.fit(X_train, y_train)\n",
        "    # ensemble by averaging predict_proba\n",
        "    probs1 = model.predict_proba(X_test)[:, 1]\n",
        "    probs2 = model2.predict_proba(X_test)[:, 1]\n",
        "    probs_ens = (probs1 + probs2) / 2.0\n",
        "    y_pred_ens = (probs_ens >= 0.5).astype(int)\n",
        "    acc_ens = accuracy_score(y_test, y_pred_ens)\n",
        "    print(\"Ensemble Accuracy:\", acc_ens)\n",
        "    if acc_ens > acc:\n",
        "        print(\"Ensemble improved accuracy — using ensemble predictions for reporting and saving.\")\n",
        "        acc = acc_ens\n",
        "        y_pred = y_pred_ens\n",
        "        # keep both models for later ensemble predictions\n",
        "        ensemble_models = (model, model2)\n",
        "    else:\n",
        "        ensemble_models = (model,)\n",
        "else:\n",
        "    ensemble_models = (model,)\n",
        "\n",
        "# Save best single model (the primary one) and feature columns\n",
        "joblib.dump(model, os.path.join(\"outputs\", \"hospital_crowd_rf_model.joblib\"))\n",
        "pd.Series(X.columns).to_csv(os.path.join(\"outputs\", \"feature_columns.csv\"), index=False)\n",
        "print(f\"\\nSaved primary model to outputs/hospital_crowd_rf_model.joblib and features to outputs/feature_columns.csv\")\n",
        "\n",
        "# -----------------------\n",
        "# 8. Plots (fixed pivot usage via pivot_table)\n",
        "# -----------------------\n",
        "# Heatmap: average num_present by day_of_week and hour\n",
        "pivot = obs.groupby([\"day_of_week\", \"hour\"])[\"num_present\"].mean().reset_index()\n",
        "heat = pivot.pivot_table(index=\"day_of_week\", columns=\"hour\", values=\"num_present\", aggfunc=\"mean\")\n",
        "\n",
        "# ensure correct weekday order\n",
        "weekday_order = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
        "# reindex rows in that order (if a day is missing it will be introduced with NaNs)\n",
        "heat = heat.reindex(weekday_order)\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.heatmap(heat, cmap=\"YlOrRd\", linewidths=0.5)\n",
        "plt.title(\"Average Number of Patients (08:00-20:00) — heatmap (day vs hour)\")\n",
        "plt.ylabel(\"Day of Week\")\n",
        "plt.xlabel(\"Hour of Day\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/heatmap_day_hour.png\", dpi=150)\n",
        "plt.close()\n",
        "print(\"Saved heatmap to outputs/heatmap_day_hour.png\")\n",
        "\n",
        "# Line plot: crowd probability over the day for each weekday (plot Wed example + overlay)\n",
        "def build_row_for_minute(day_abbr, minute_of_day):\n",
        "    row = {}\n",
        "    row[\"sin_time\"] = np.sin(2 * np.pi * minute_of_day / (24*60))\n",
        "    row[\"cos_time\"] = np.cos(2 * np.pi * minute_of_day / (24*60))\n",
        "    row[\"minute_of_day\"] = minute_of_day\n",
        "    row[\"hour\"] = minute_of_day // 60\n",
        "    row[\"minute\"] = minute_of_day % 60\n",
        "    row[\"is_weekend\"] = 1 if day_abbr in [\"Sat\", \"Sun\"] else 0\n",
        "    # add day dummies\n",
        "    for col in X.columns:\n",
        "        if col.startswith(\"day_of_week_\"):\n",
        "            row[col] = 1 if col == f\"day_of_week_{day_abbr}\" else 0\n",
        "    # ensure column order\n",
        "    return pd.DataFrame([row], columns=X.columns).fillna(0)\n",
        "\n",
        "example_day = \"Wed\"\n",
        "minutes_eval = list(range(8*60, 20*60, 10))\n",
        "probs = []\n",
        "for m in minutes_eval:\n",
        "    xrow = build_row_for_minute(example_day, m)\n",
        "    # ensemble prediction if ensemble_models has two models\n",
        "    if len(ensemble_models) == 2:\n",
        "        p = (ensemble_models[0].predict_proba(xrow)[0,1] + ensemble_models[1].predict_proba(xrow)[0,1]) / 2\n",
        "    else:\n",
        "        p = ensemble_models[0].predict_proba(xrow)[0,1]\n",
        "    probs.append(p)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot([f\"{m//60:02d}:{m%60:02d}\" for m in minutes_eval], probs, marker=\"o\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Time of Day\")\n",
        "plt.ylabel(\"Predicted Probability (Crowded)\")\n",
        "plt.title(f\"Predicted Crowd Probability across the day — {example_day}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/crowd_prob_line_Wed.png\", dpi=150)\n",
        "plt.close()\n",
        "print(\"Saved line plot to outputs/crowd_prob_line_Wed.png\")\n",
        "\n",
        "# Class distribution plot (before)\n",
        "before = obs[\"Crowded\"].value_counts(normalize=True).sort_index()\n",
        "# After: show predictions on the entire dataset (quick check)\n",
        "all_X = X.copy()\n",
        "# ensemble predictions (if ensemble)\n",
        "if len(ensemble_models) == 2:\n",
        "    p1 = ensemble_models[0].predict_proba(all_X)[:,1]\n",
        "    p2 = ensemble_models[1].predict_proba(all_X)[:,1]\n",
        "    pr\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}